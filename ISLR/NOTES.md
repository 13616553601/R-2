# 线性回归 #
面对一个数据集，比如Advertising，包括四个变量，sales，TV，radio，newspaper。我们要问几个问题：

1. 广告预算与销售额之间有关系吗？
2. 如果有上述关系，这种关系有多强？
3. 哪种广告媒介影响销售额？
4. 广告媒介对销售额的影响能准确估计吗？
5. 能准确预测未来的销售额吗？
6. 广告支出与销售额之间的关系是线性的吗？
7. 广告媒介之间存在协同效应吗？

## 简单线性回归 ##
假设$X$和$Y$之间近似存在线性关系：
$$Y\approx \beta_0 + \beta_1 X.$$
一旦获得了参数的估计值$\hat{\beta}_0,\hat{\beta}_1$，我们就可以根据某个特定的$X$，预测$Y$：
$$\hat{y}=\hat{\beta}_0 + \hat{\beta}_1 x,$$
其中，$\hat{y}$表示在$X=x$时$Y$的一个预测。

我们要找到最能够拟合数据集的参数估计，使得组成的直线尽可能靠近数据点。有多种方式来衡量“近”，最常用的方法之一是最小二乘法（OLS）。简单线性回归的OLS估计为：
$$\hat{\beta}_1 = \frac{\sum_{i=1}^n (x_i -\bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2},$$
$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x},$$
其中，$\bar{y},\bar{x}$为样本均值。

## 多元线性回归 ##
$$Y=\beta_0 + \beta_1 X_1 + \beta_2 X_2 + \cdots + \beta_p X_p + \epsilon.$$

作多元回归，一般要回答四个问题：

1. 响应变量和自变量之间相关吗？
2. 是否所有的自变量都能解释Y，抑或只有一部分有用？
3. 模型对数据的拟合程度如何？
4. 给定自变量值，如何预测响应变量的值？预测的准确性如何？

### 问题1：响应变量与自变量之间有关系吗？ ###
对于这个问题，可以用F检验。原假设为所有的参数均为0：
$$ H_0:\beta_1 = \beta_2 = \cdots = \beta_p = 0;\quad H_a: \exists j,\beta_j\neq 0.$$
构造F统计量：
$$F=\frac{(\mathrm{TSS}-\mathrm{RSS})/p}{\mathrm{RSS}/(n-p-1)},$$
可以证明，当原假设为真时，上述统计量中分子和分母的期望值均为$\sigma^2$（误差方差），因此，如果自变量和响应变量不存在关系，F统计量应该接近1。到底F多大时，可以拒绝原假设？这要看$n$和$p$的大小。当$n$较大时，即使F统计量只比1稍大也可以拒绝原假设。反之，当$n$比较小时，需要更大的F值。当$H_0$为真且误差项服从正态分布时，F统计量服从F分布。由此，可以从相应的p值来判断是否可以拒绝原假设。

（TODO：F检验与t检验的关系，为何需要F检验？）

### 问题2：哪些变量是重要的？###
多元回归分析的第一步，是计算F统计量并检查相应的p值。如果这一步得出至少有一个自变量与响应变量有关，那么很自然地，我们要找出哪些是重要的（应该进入模型），这项任务称为“变量选择”。我们可以查看每一个变量的p值（t检验），但是如果自变量数量很多（p很大），这种办法会导致错误。

通过选取不同的变量，可以生成$2^p$个模型。当$p$较大时，尝试所有的模型显然是不切实际的。我们需要一种自动且有效的方法来选取一部分模型进行考虑。有三种传统办法：

* 前向选择。
* 后向选择。当$p>n$时不可用。
* 混合选择。

### 问题3：模型拟合性 ###
最常用的两个衡量拟合性的数值是RSE和$R^2$。一元回归中，$R^2=\mathrm{Cov}(X,Y)^2$；在多元线性回归中，$R^2=\mathrm{Cov}(Y,\hat{Y})^2$。事实上，拟合线性模型的一个性质就是，使这个相关系数在所有线性模型中最大。

除了看RSE和R方，还可以通过图形来观察。在销售额的例子中，如果作出sales ~ TV + radio的三维图，从残差的分布情况可以看到，变量之间存在非线性，意味着可能需要加入交互项（协同效应）。

### 问题4：预测 ###
利用回归得到的参数估计来预测，会面临三类不确定性：

1. 可减少误差。来自OLS回归平面$\hat{Y}$与真实总体回归平面$f(X)$之间的差距，可以由置信区间来表示。
2. 模型偏差。来自线性模型与实际不符产生的误差，这种误差也是可减少的。
3. 不可减少误差。即使我们知道真实的参数，也会面临由随机误差项带来的不可减少的误差。也就是$Y$与$\hat{Y}$的差距。可以用预测区间来表示。

（TODO：预测区间与置信区间的区别？）

## 回归模型中的其他问题 ##

### 定性预测子 ###
定性变量一般称为因子（factor），其可能的取值称为水平（level）。对于仅有两个水平的因子，将其加入模型是非常简单的，只要构造一个哑变量。比如，对于gender变量，可以构造一个新的变量$x_i$，当第$i$个人为女性时取1，反之取0。相应的回归模型可以写成：
$$
\begin{eqnarray}
y_i = \beta_0 + \beta_1 x_i + \epsilon_i =
\begin{cases}
\beta_0 + \beta_1 + \epsilon_i       & \mathrm{第i个为女性} \\
\beta_0 + \epsilon_i       & \mathrm{第i个为男性}
\end{cases}
\end{eqnarray}
$$
回归系数的解释：
对于取三个可能值的变量，可以定义两个亚变量，模型参数的解释类似。定性变量的编码方式不唯一，但不同方式都将得到同样的模型拟合结果，只是系数及其解释不同（都表示某种比较）。

### 线性模型的拓展 ###
标准线性回归模型带有很多假设，其中涉及自变量和应变量关系的两个重要假设是可加性（additive）和线性（linear）。
